{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AllenNLP Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b3a9630>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosDatasetReader(DatasetReader):\n",
    "    def __init__(self, token_indexers=None):\n",
    "        super().__init__(lazy=False)\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        \n",
    "    def text_to_instance(self, tokens, tags=None):\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"sentence\": sentence_field}\n",
    "        \n",
    "        if tags:\n",
    "            label_field = SequenceLabelField(labels=tags, sequence_field=sentence_field)\n",
    "            fields[\"labels\"] = label_field\n",
    "        \n",
    "        return Instance(fields)\n",
    "    \n",
    "    def _read(self, file_path):\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                pairs = line.strip().split()\n",
    "                sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n",
    "                yield self.text_to_instance([Token(word) for word in sentence], tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmTagger(Model):\n",
    "    \n",
    "    def __init__(self, word_embeddings, encoder, vocab):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
    "                                          out_features=vocab.get_vocab_size('labels'))\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        \n",
    "    def forward(self, sentence, labels=None):\n",
    "        mask = get_text_field_mask(sentence)\n",
    "        embeddings = self.word_embeddings(sentence)\n",
    "        encoder_out = self.encoder(embeddings, mask)\n",
    "        tag_logits = self.hidden2tag(encoder_out)\n",
    "        output = {\"tag_logits\": tag_logits}\n",
    "        \n",
    "        if labels is not None:\n",
    "            self.accuracy(tag_logits, labels, mask)\n",
    "            output[\"loss\"] = sequence_cross_entropy_with_logits(tag_logits, labels, mask)\n",
    "        return output\n",
    "    \n",
    "    def get_metrics(self, reset):\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PosDatasetReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 831.30it/s]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 724.97it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(cached_path(\n",
    "    'https://raw.githubusercontent.com/allenai/allennlp'\n",
    "    '/master/tutorials/tagger/training.txt'))\n",
    "validation_dataset = reader.read(cached_path(\n",
    "    'https://raw.githubusercontent.com/allenai/allennlp'\n",
    "    '/master/tutorials/tagger/validation.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/02/2020 09:01:41 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00, 2890.13it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size(\"tokens\"),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "model = LstmTagger(word_embeddings, lstm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "iterator = BucketIterator(batch_size=2, sorting_keys=[(\"sentence\", \"num_tokens\")])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Beginning training.\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 0/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0875 ||: 100%|██████████| 1/1 [00:00<00:00, 74.80it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0573 ||: 100%|██████████| 1/1 [00:00<00:00, 162.91it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.088  |     0.057\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:01\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 1/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0564 ||: 100%|██████████| 1/1 [00:00<00:00, 45.29it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0380 ||: 100%|██████████| 1/1 [00:00<00:00, 146.52it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.056  |     0.038\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 2/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0372 ||: 100%|██████████| 1/1 [00:00<00:00, 49.15it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0259 ||: 100%|██████████| 1/1 [00:00<00:00, 100.29it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.037  |     0.026\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 3/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0253 ||: 100%|██████████| 1/1 [00:00<00:00, 75.76it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0183 ||: 100%|██████████| 1/1 [00:00<00:00, 126.12it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.025  |     0.018\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 4/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0178 ||: 100%|██████████| 1/1 [00:00<00:00, 66.85it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0133 ||: 100%|██████████| 1/1 [00:00<00:00, 77.21it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.018  |     0.013\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 5/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0129 ||: 100%|██████████| 1/1 [00:00<00:00, 95.98it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0099 ||: 100%|██████████| 1/1 [00:00<00:00, 83.22it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.013  |     0.010\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 6/9\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0096 ||: 100%|██████████| 1/1 [00:00<00:00, 74.83it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0076 ||: 100%|██████████| 1/1 [00:00<00:00, 103.64it/s]\u001b[A02/02/2020 09:02:33 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   loss          |     0.010  |     0.008\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:33 - INFO - allennlp.training.trainer -   Epoch 7/9\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0073 ||: 100%|██████████| 1/1 [00:00<00:00, 115.86it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0059 ||: 100%|██████████| 1/1 [00:00<00:00, 196.69it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   loss          |     0.007  |     0.006\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Epoch 8/9\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0057 ||: 100%|██████████| 1/1 [00:00<00:00, 148.19it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0048 ||: 100%|██████████| 1/1 [00:00<00:00, 133.45it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   loss          |     0.006  |     0.005\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:00\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Epoch 9/9\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 203.85792\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Training\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0046 ||: 100%|██████████| 1/1 [00:00<00:00, 59.01it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Validating\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 1.0000, loss: 0.0039 ||: 100%|██████████| 1/1 [00:00<00:00, 227.90it/s]\u001b[A02/02/2020 09:02:34 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   cpu_memory_MB |   203.858  |       N/A\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   accuracy      |     1.000  |     1.000\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   loss          |     0.005  |     0.004\n",
      "02/02/2020 09:02:34 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'peak_cpu_memory_MB': 203.85792,\n",
       " 'training_duration': '00:00:00',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 9,\n",
       " 'epoch': 9,\n",
       " 'training_accuracy': 1.0,\n",
       " 'training_loss': 0.004572445061057806,\n",
       " 'training_cpu_memory_MB': 203.85792,\n",
       " 'validation_accuracy': 1.0,\n",
       " 'validation_loss': 0.003880667733028531,\n",
       " 'best_epoch': 9,\n",
       " 'best_validation_accuracy': 1.0,\n",
       " 'best_validation_loss': 0.003880667733028531}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=validation_dataset,\n",
    "                  patience=10,\n",
    "                  num_epochs=10,\n",
    "                  cuda_device=cuda_device)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SentenceTaggerPredictor(model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_logits = predictor.predict(\"The dog ate the apple\")['tag_logits']\n",
    "tag_ids = np.argmax(tag_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NN', 'V', 'DET', 'NN']\n"
     ]
    }
   ],
   "source": [
    "print([model.vocab.get_token_from_index(i, 'labels') for i in tag_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
