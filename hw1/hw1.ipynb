{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3-A2teSE33Ip"
      },
      "source": [
        "### HW1 Text Classifier\n",
        "---\n",
        "\n",
        "#### Setting Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uR0QbHxyxG8u",
        "outputId": "cb4414d5-f1f7-4634-fe8b-d3c0bdaf04ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget http://phontron.com/data/topicclass-v1.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-04 20:02:43--  http://phontron.com/data/topicclass-v1.tar.gz\n",
            "Resolving phontron.com (phontron.com)... 208.113.196.149\n",
            "Connecting to phontron.com (phontron.com)|208.113.196.149|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15665160 (15M) [application/gzip]\n",
            "Saving to: ‘topicclass-v1.tar.gz’\n",
            "\n",
            "\rtopicclass-v1.tar.g   0%[                    ]       0  --.-KB/s               \rtopicclass-v1.tar.g  13%[=>                  ]   2.01M  10.1MB/s               \rtopicclass-v1.tar.g 100%[===================>]  14.94M  45.2MB/s    in 0.3s    \n",
            "\n",
            "2020-02-04 20:02:44 (45.2 MB/s) - ‘topicclass-v1.tar.gz’ saved [15665160/15665160]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWh76FTtxLer",
        "outputId": "0cc06a0b-7a36-4e4a-9690-45e5ad3511d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!tar -xvzf topicclass-v1.tar.gz topicclass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topicclass/\n",
            "topicclass/topicclass_valid.txt\n",
            "topicclass/topicclass_test.txt\n",
            "topicclass/topicclass_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7UoIBRfq30dM"
      },
      "source": [
        "#### Data Preprocessing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wFETkOfbx7Op",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "  with open(path, \"r\") as f:\n",
        "    data = f.readlines()\n",
        "  labels, text = zip(*map(lambda x: x.split(\"|||\"), data))\n",
        "  \n",
        "  labels = map(lambda x: x.strip(\"\\n\").strip().lower(), labels)\n",
        "  labels = list(map(lambda x: \"media and drama\" if \"media and darama\" in x else x, labels))\n",
        "  text = list(map(lambda x: x.strip(\"\\n\").strip().lower(), text))\n",
        "  return text, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6OXjBqyex7Rl",
        "colab": {}
      },
      "source": [
        "train_x, train_y = read_data(\"topicclass/topicclass_train.txt\")\n",
        "valid_x, valid_y = read_data(\"topicclass/topicclass_valid.txt\")\n",
        "test_x, test_y = read_data(\"topicclass/topicclass_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YaVfanQryWPU",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "word_tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "def clean_string(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for all datasets except for SST.\n",
        "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`\\-\\_]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\\\\", \" \", string)\n",
        "    string = re.sub(r\"\\s+\", \" \", string)\n",
        "    return string.strip()\n",
        "\n",
        "def tokenize(string):\n",
        "    # return list(map(lemmatizer.lemmatize, word_tokenizer.tokenize(string)))\n",
        "    return  word_tokenizer.tokenize(string)\n",
        "\n",
        "def preprocess(texts):\n",
        "    texts = map(clean_string, texts)\n",
        "    texts = map(tokenize, texts)\n",
        "    return list(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bNNlB6B0yWUV",
        "outputId": "68db041d-9526-47ee-9d82-286a60d9a3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "%time train_x = preprocess(train_x)\n",
        "%time valid_x = preprocess(valid_x)\n",
        "%time test_x = preprocess(test_x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 35.3 s, sys: 222 ms, total: 35.5 s\n",
            "Wall time: 35.5 s\n",
            "CPU times: user 84.9 ms, sys: 0 ns, total: 84.9 ms\n",
            "Wall time: 85.1 ms\n",
            "CPU times: user 92.8 ms, sys: 0 ns, total: 92.8 ms\n",
            "Wall time: 92.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eDZnzu201NRq",
        "outputId": "b0bdb263-783f-49f3-e5ea-ef15ab0bc242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "len_train = list(map(len, train_x))\n",
        "pd.Series(len_train).quantile(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XnI6mBbYyWSl",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Vocab(object):\n",
        "  \n",
        "  def __init__(self, L):\n",
        "    if isinstance(L[0], list):\n",
        "      tokens = list(itertools.chain(*L))\n",
        "      self.token_counts = pd.Series(tokens).value_counts().to_frame().sort_index(ascending=True)\n",
        "      self.vocab = [\"unk\"] + self.token_counts.index.to_list()\n",
        "    else:\n",
        "      tokens = self.token_counts = pd.Series(L).value_counts().to_frame().sort_index(ascending=True)\n",
        "      self.vocab = self.token_counts.index.to_list()\n",
        "    self.w2i = dict(zip(self.vocab, range(len(self.vocab))))\n",
        "    self.i2w = dict(zip(range(len(self.vocab)), self.vocab))\n",
        "\n",
        "  def map_words2index(self, L):\n",
        "    return list(map(lambda x: self.w2i[x] if x in self.w2i else self.w2i['unk'], L))\n",
        "\n",
        "  def map_index2words(self, L):\n",
        "    return list(map(lambda x: self.i2w[x], L))\n",
        "\n",
        "  def map_dataset_words2index(self, L):\n",
        "    return np.array(list(map(self.map_words2index, L)))\n",
        "\n",
        "  def map_dataset_index2words(self, L):\n",
        "    return np.array(list(map(self.map_index2words, L)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bt8Ig3B91pcL",
        "outputId": "d9620dc7-c09b-460d-973c-58b56f0ed5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "%time vocab = Vocab(train_x + valid_x)\n",
        "%time train_x = vocab.map_dataset_words2index(train_x)\n",
        "%time valid_x = vocab.map_dataset_words2index(valid_x)\n",
        "%time test_x = vocab.map_dataset_words2index(test_x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.71 s, sys: 65 ms, total: 1.77 s\n",
            "Wall time: 1.78 s\n",
            "CPU times: user 3.07 s, sys: 32 ms, total: 3.1 s\n",
            "Wall time: 3.1 s\n",
            "CPU times: user 7.53 ms, sys: 9 µs, total: 7.54 ms\n",
            "Wall time: 7.51 ms\n",
            "CPU times: user 7.22 ms, sys: 153 µs, total: 7.38 ms\n",
            "Wall time: 7.35 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AuJJA1Fn1pi4",
        "outputId": "690d9271-ca0a-4890-fafd-ca5ce7dc8777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(vocab.vocab))\n",
        "train_x_ = vocab.map_dataset_index2words(train_x)\n",
        "\" \".join(train_x_[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'several of these rights regulate pre - trial procedure access to a non - excessive bail , the right to indictment by a grand jury , the right to an information ( charging document ) , the right to a speedy trial , and the right to be tried in a specific venue'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nFwreiw01pfA",
        "outputId": "b700b00a-4adc-43fa-eb32-94cc9ae0386e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "label_vocab = Vocab(train_y + valid_y)\n",
        "label_vocab.w2i"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agriculture, food and drink': 0,\n",
              " 'art and architecture': 1,\n",
              " 'engineering and technology': 2,\n",
              " 'geography and places': 3,\n",
              " 'history': 4,\n",
              " 'language and literature': 5,\n",
              " 'mathematics': 6,\n",
              " 'media and drama': 7,\n",
              " 'miscellaneous': 8,\n",
              " 'music': 9,\n",
              " 'natural sciences': 10,\n",
              " 'philosophy and religion': 11,\n",
              " 'social sciences and society': 12,\n",
              " 'sports and recreation': 13,\n",
              " 'video games': 14,\n",
              " 'warfare': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_1bpNf7_84BN",
        "colab": {}
      },
      "source": [
        "train_y = label_vocab.map_words2index(train_y)\n",
        "valid_y = label_vocab.map_words2index(valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcCgk4-C-vu6",
        "outputId": "d2930d2f-ed1d-4caa-de63-ff7297011132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "\n",
        "# train_y = to_categorical(train_y, num_classes=17)\n",
        "# train_y = list(map(list, train_y))\n",
        "# valid_y = to_categorical(valid_y, num_classes=17)\n",
        "# valid_y = list(map(list, valid_y))\n",
        "valid_y[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13, 13, 13, 7, 9, 9, 9, 7, 12, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XcRBl0KyStAU"
      },
      "source": [
        "#### Dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytengrB2StVg",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, LongTensor\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from IPython.core.debugger import set_trace\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmlh9vnMStc_",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, Y=None):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.Y is not None:\n",
        "      return (self.X[idx], self.Y[idx])\n",
        "    return (self.X[idx], None)\n",
        "\n",
        "def pad(seq, seq_lengths, pad_after=True):\n",
        "  max_seq_len = max(seq_lengths)\n",
        "  seq_tensor = Variable(torch.zeros((len(seq), max_seq_len))).long()\n",
        "  # pad input tensor\n",
        "  for idx, seq in enumerate(seq):\n",
        "    seq_len = seq_lengths[idx]\n",
        "    if pad_after:\n",
        "      seq_tensor[idx, :seq_len] = LongTensor(np.asarray(seq).astype(int))\n",
        "    else: \n",
        "      # pad before\n",
        "      seq_tensor[idx, max_seq_len-seq_len:] = LongTensor(np.asarray(seq).astype(int))\n",
        "  return seq_tensor\n",
        "\n",
        "def batchify(data):\n",
        "  X, Y = tuple(map(list, zip(*data)))\n",
        "  seq_lengths = LongTensor([len(x) for x in X])\n",
        "  X = pad(X, seq_lengths, pad_after=True)\n",
        "  Y = LongTensor(Y)\n",
        "  return X, Y\n",
        "\n",
        "def batchify_test(data):\n",
        "  X, Y = tuple(map(list, zip(*data)))\n",
        "  seq_lengths = LongTensor([len(x) for x in X])\n",
        "  X = pad(X, seq_lengths, pad_after=True)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "train = MyDataset(train_x, train_y)\n",
        "valid = MyDataset(valid_x, valid_y)\n",
        "test = MyDataset(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BWkiAoWStks",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train, batch_size=64, shuffle=True, collate_fn=batchify)\n",
        "valid_loader = DataLoader(valid, batch_size=64, shuffle=False, collate_fn=batchify)\n",
        "test_loader = DataLoader(test, batch_size=64, shuffle=False, collate_fn=batchify_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZE7E6FYw3vZK"
      },
      "source": [
        "#### Model Fitting\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-4Q8oVzxTsl",
        "colab": {}
      },
      "source": [
        "from torch import nn, LongTensor, Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kIY40pvY9fgR",
        "colab": {}
      },
      "source": [
        "import time\n",
        "def accuracy(preds, y):\n",
        "  return (np.array(preds) == np.array(y)).astype(int).mean()\n",
        "\n",
        "\n",
        "def train_epoch(epoch, model, optimizer, criterion):\n",
        "  model.train()\n",
        "  train_loss, n_data = 0, 0\n",
        "  start = time.time()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  for i, (x, y) in enumerate(train_loader):\n",
        "    n_data += x.size()[0]\n",
        "    labels.extend(y.tolist())\n",
        "    if is_cuda: x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    preds.extend(out.argmax(axis=1).tolist())\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()\n",
        "    if grad_clip: torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "    optimizer.step()\n",
        "    train_loss += loss\n",
        "    if i % print_iter == print_iter - 1:\n",
        "      model, valid_preds, valid_labels, valid_loss = validate(model, criterion)\n",
        "      print(\"\"\"epoch {} - batch [{}/{}] - train loss: {:.2f} - acc: {:.3f} - valid loss : {:.2f} - acc : {:.3f} time taken: {:.2f}\"\"\".format(epoch, i, \n",
        "            len(train_loader), train_loss/(i+1),\n",
        "            accuracy(preds, labels), valid_loss, accuracy(valid_preds, valid_labels),\n",
        "            time.time()-start), flush=True)\n",
        "      \n",
        "      model.train()\n",
        "      start = time.time()\n",
        "      train_loss = 0\n",
        "\n",
        "  # end of epoch\n",
        "  model, valid_preds, valid_labels, valid_loss = validate(model, criterion)\n",
        "  print(\"\"\"epoch {} - batch [{}/{}] - train loss: {:.2f} - acc: {:.3f} - valid loss : {:.2f} - acc : {:.3f} time taken: {:.2f}\"\"\".format(epoch, i, \n",
        "        len(train_loader), train_loss/(i+1),\n",
        "        accuracy(preds, labels), valid_loss, accuracy(valid_preds, valid_labels),\n",
        "        time.time()-start), flush=True)\n",
        "  return model\n",
        "\n",
        "def learning_rate_decay(optimizer):\n",
        "  for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * 0.1\n",
        "  return optimizer\n",
        "\n",
        "def training(model, epoches, lr, wd):\n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  for ep in range(epoches):\n",
        "    model = train_epoch(ep, model, optimizer, criterion)\n",
        "    optimizer = learning_rate_decay(optimizer)\n",
        "  return model\n",
        "\n",
        "def validate(model, criterion):\n",
        "  model.eval()\n",
        "  valid_loss = 0\n",
        "  preds, labels = [], []\n",
        "  for i, (x, y) in enumerate(valid_loader):\n",
        "    labels.extend(y.tolist())\n",
        "    if torch.cuda.is_available(): x, y = x.cuda(), y.cuda()\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "    preds.extend(out.argmax(axis=1).tolist())\n",
        "    valid_loss += loss\n",
        "  return model, preds, labels, valid_loss/(i+1)\n",
        "    \n",
        "def predict(model, loader):\n",
        "  model.eval()\n",
        "  preds, labels = [], []\n",
        "  for i, (x, _) in enumerate(loader):\n",
        "    if torch.cuda.is_available(): x = x.cuda()\n",
        "    out = model(x)\n",
        "    preds.extend(out.argmax(axis=1).tolist())\n",
        "  return preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Zv3GeBOXZ_y"
      },
      "source": [
        "#### Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fnH8gLLVXZNQ",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "class LSTM_clf(nn.Module):\n",
        "\n",
        "  def __init__(self, embed_dim, hidden_dim, vocab_size, out_size, \n",
        "               layers=1, bidirectional=False):\n",
        "    super(LSTM_clf, self).__init__()\n",
        "    self.word_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.net = nn.LSTM(embed_dim, hidden_dim,  num_layers=layers, \n",
        "                       bidirectional=bidirectional, dropout=0.5)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn = nn.BatchNorm1d(hidden_dim * (int(bidirectional) + 1))\n",
        "    self.linear = nn.Linear(hidden_dim * (int(bidirectional) + 1), out_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.word_embedding(x)\n",
        "    out = self.net(out)[0]\n",
        "    out = self.relu(out).transpose(1,2)\n",
        "    out = F.max_pool1d(out, out.size()[2]).squeeze()\n",
        "    out = self.linear(self.bn(out))\n",
        "    return out\n",
        "\n",
        "class DCNN_block(nn.Module):\n",
        "  \n",
        "  def __init__(self, embed_dim, hidden_dim, kernel_size, dilations=None,\n",
        "               dropout=0.2):\n",
        "    super(DCNN_block, self).__init__()\n",
        "    self.conv1 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, dilation=1))\n",
        "    self.conv2 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, dilation=2))\n",
        "    self.conv3 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, dilation=4))\n",
        "    self.net = nn.Sequential(self.conv1, nn.ReLU(), nn.Dropout(dropout),\n",
        "                             self.conv2, nn.ReLU(), nn.Dropout(dropout), \n",
        "                             self.conv3, nn.ReLU(), nn.Dropout(dropout))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # N x C x L\n",
        "    return self.net(x)\n",
        "\n",
        "class DCNN_rez_block(nn.Module):\n",
        "  \n",
        "  def __init__(self, embed_dim, hidden_dim, kernel_size, dilations=None,\n",
        "               dropout=0.2):\n",
        "    super(DCNN_rez_block, self).__init__()\n",
        "    self.conv1 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, \n",
        "                                       padding=(kernel_size-1)*1, dilation=1))\n",
        "    self.conv2 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, \n",
        "                                       padding=(kernel_size-1)*2, dilation=2))\n",
        "    self.conv3 = weight_norm(nn.Conv1d(embed_dim, hidden_dim, kernel_size, \n",
        "                                       padding=(kernel_size-1)*4, dilation=4))\n",
        "\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.relu3 = nn.ReLU()\n",
        "\n",
        "    self.do1 = nn.Dropout(dropout)\n",
        "    self.do2 = nn.Dropout(dropout)\n",
        "    self.do3 = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # N x C x L\n",
        "    seq_len = x.size()[2]\n",
        "    out = self.do1(self.relu1(self.conv1(x)))[:, :, -seq_len:]\n",
        "    out = out + self.do2(self.relu2(self.conv2(x)))[:, :, -seq_len:]\n",
        "    out = out + self.do3(self.relu3(self.conv3(x)))[:, :, -seq_len:]\n",
        "    return out\n",
        "\n",
        "\n",
        "class DCNN(nn.Module):\n",
        "\n",
        "  def __init__(self, embed_dim, hidden_dim, vocab_size, out_size, \n",
        "               kernel_size, dilations=None, rez_block=True, \n",
        "               dropout=0.2):\n",
        "    super(DCNN, self).__init__()\n",
        "    self.word_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    if rez_block: \n",
        "      self.net = DCNN_rez_block(embed_dim, hidden_dim, kernel_size, dilations, dropout)\n",
        "    else:\n",
        "      self.net = DCNN_block(embed_dim, hidden_dim, kernel_size, dilations, dropout)\n",
        "    self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "    self.do = nn.Dropout(dropout)\n",
        "    self.linear = nn.Linear(hidden_dim, out_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.word_embedding(x)\n",
        "    out = self.net(out.transpose(1,2))\n",
        "    out = F.max_pool1d(out, out.size()[2]).squeeze()\n",
        "    out = self.linear(self.do(self.bn(out)))\n",
        "    return out\n",
        "\n",
        "\n",
        "class DDCNN(nn.Module):\n",
        "  # Dilated and Dense CNN\n",
        "  def __init__(self, embed_dim, hidden_dim, vocab_size, out_size, \n",
        "               kernel_size, dilations=None, rez_block=True, \n",
        "               dropout=0.2):\n",
        "    super(DDCNN, self).__init__()\n",
        "    self.word_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    if rez_block: \n",
        "      self.dcnn = DCNN_rez_block(embed_dim, hidden_dim, kernel_size, dilations, dropout)\n",
        "    else:\n",
        "      self.dcnn = DCNN_block(embed_dim, hidden_dim, kernel_size, dilations, dropout)\n",
        "\n",
        "    self.do1 = nn.Dropout(dropout)\n",
        "    self.do2 = nn.Dropout(dropout)\n",
        "    self.do3 = nn.Dropout(dropout)\n",
        "    self.cnn1 = weight_norm(nn.Conv1d(embed_dim, int(hidden_dim//3), 4, padding=3, dilation=1))\n",
        "    self.cnn2 = weight_norm(nn.Conv1d(embed_dim, int(hidden_dim//3), 6, padding=5, dilation=1))\n",
        "    self.cnn3 = weight_norm(nn.Conv1d(embed_dim, int(hidden_dim//3), 8, padding=7, dilation=1))\n",
        "    \n",
        "    self.bn = nn.BatchNorm1d(hidden_dim*2)\n",
        "    self.do = nn.Dropout(dropout)\n",
        "    self.linear = nn.Linear(hidden_dim*2, out_size)\n",
        "\n",
        "  def cnn(self, x):\n",
        "    out1 = F.relu(self.cnn1(self.do1(x)))\n",
        "    out2 = F.relu(self.cnn2(self.do2(x)))\n",
        "    out3 = F.relu(self.cnn3(self.do3(x)))\n",
        "    outs = []\n",
        "    for o in [out1, out2, out3]:\n",
        "      outs.append(F.max_pool1d(o, o.size()[2]).squeeze())\n",
        "    out = torch.cat(outs, 1)\n",
        "    return out\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.word_embedding(x).transpose(1,2)\n",
        "    dcnn_out = self.dcnn(out)\n",
        "    cnn_out = self.cnn(out)\n",
        "    dcnn_out = F.max_pool1d(dcnn_out, dcnn_out.size()[2]).squeeze()\n",
        "    out = self.linear(self.do(self.bn(torch.cat((dcnn_out,cnn_out), 1))))\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "frS_s9lqxVlh",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "bs = 64\n",
        "n_class = 16\n",
        "epochs = 3\n",
        "lstm_hidden = 300\n",
        "cnn_hidden = 300\n",
        "embed_dim = 300\n",
        "layers = 2\n",
        "kernel_size = 3\n",
        "vocab_size = len(vocab.vocab)\n",
        "is_cuda = torch.cuda.is_available()\n",
        "lr = 0.002\n",
        "grad_clip = 1\n",
        "print_iter = 500\n",
        "lstm1 = LSTM_clf(embed_dim, lstm_hidden, vocab_size, n_class, layers)\n",
        "dcnn1 = DCNN(embed_dim, cnn_hidden, vocab_size, n_class, 3, \n",
        "             rez_block=False, dropout=0.2)\n",
        "dcnn_rez1 = DCNN(500, 500, vocab_size, n_class, 5, \n",
        "                 rez_block=True, dropout=0.2)\n",
        "dcnn_rez2 = DCNN(embed_dim, 300, vocab_size, n_class, 3, \n",
        "                 rez_block=True, dropout=0.2)\n",
        "dcnn_rez3 = DCNN(embed_dim, 500, vocab_size, n_class, 3, \n",
        "                 rez_block=True, dropout=0.3)\n",
        "ddcnn_rez1 = DDCNN(500, 600, vocab_size, n_class, 5, \n",
        "                 rez_block=True, dropout=0.2)\n",
        "ddcnn_rez2 = DDCNN(embed_dim, 150, vocab_size, n_class, 3, \n",
        "                 rez_block=True, dropout=0.2)\n",
        "ddcnn_rez3 = DDCNN(embed_dim, 300, vocab_size, n_class, 3, \n",
        "                 rez_block=True, dropout=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RcYULph68b_g",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train, batch_size=bs, shuffle=True, collate_fn=batchify)\n",
        "valid_loader = DataLoader(valid, batch_size=bs, shuffle=False, collate_fn=batchify)\n",
        "test_loader = DataLoader(test, batch_size=bs, shuffle=False, collate_fn=batchify_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQ8X4mqfx_2",
        "colab_type": "code",
        "outputId": "106ca2db-5878-4761-a179-f8c487cf1e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "%time training(ddcnn_rez1, 2, 2e-3, 1e-4)  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.80 - acc: 0.472 - valid loss : 1.36 - acc : 0.605 time taken: 36.47\n",
            "epoch 0 - batch [999/3968] - train loss: 0.70 - acc: 0.533 - valid loss : 1.17 - acc : 0.672 time taken: 37.48\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.41 - acc: 0.568 - valid loss : 0.86 - acc : 0.712 time taken: 37.18\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.27 - acc: 0.596 - valid loss : 0.92 - acc : 0.726 time taken: 37.39\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.21 - acc: 0.614 - valid loss : 0.96 - acc : 0.747 time taken: 37.31\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.16 - acc: 0.631 - valid loss : 0.85 - acc : 0.770 time taken: 37.36\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.645 - valid loss : 0.90 - acc : 0.773 time taken: 37.48\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.10 - acc: 0.655 - valid loss : 0.86 - acc : 0.795 time taken: 35.10\n",
            "epoch 1 - batch [499/3968] - train loss: 0.62 - acc: 0.814 - valid loss : 0.85 - acc : 0.810 time taken: 36.97\n",
            "epoch 1 - batch [999/3968] - train loss: 0.30 - acc: 0.816 - valid loss : 0.82 - acc : 0.823 time taken: 36.87\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.19 - acc: 0.818 - valid loss : 0.82 - acc : 0.823 time taken: 36.98\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.14 - acc: 0.820 - valid loss : 0.80 - acc : 0.813 time taken: 36.98\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.11 - acc: 0.821 - valid loss : 0.82 - acc : 0.820 time taken: 37.02\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.09 - acc: 0.822 - valid loss : 0.78 - acc : 0.824 time taken: 37.03\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.08 - acc: 0.823 - valid loss : 0.79 - acc : 0.821 time taken: 36.99\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.06 - acc: 0.824 - valid loss : 0.80 - acc : 0.823 time taken: 34.68\n",
            "CPU times: user 6min 31s, sys: 3min 16s, total: 9min 47s\n",
            "Wall time: 9min 59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDCNN(\n",
              "  (word_embedding): Embedding(113157, 500)\n",
              "  (dcnn): DCNN_rez_block(\n",
              "    (conv1): Conv1d(500, 600, kernel_size=(5,), stride=(1,), padding=(4,))\n",
              "    (conv2): Conv1d(500, 600, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
              "    (conv3): Conv1d(500, 600, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.2, inplace=False)\n",
              "    (do2): Dropout(p=0.2, inplace=False)\n",
              "    (do3): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (do1): Dropout(p=0.2, inplace=False)\n",
              "  (do2): Dropout(p=0.2, inplace=False)\n",
              "  (do3): Dropout(p=0.2, inplace=False)\n",
              "  (cnn1): Conv1d(500, 200, kernel_size=(4,), stride=(1,), padding=(3,))\n",
              "  (cnn2): Conv1d(500, 200, kernel_size=(6,), stride=(1,), padding=(5,))\n",
              "  (cnn3): Conv1d(500, 200, kernel_size=(8,), stride=(1,), padding=(7,))\n",
              "  (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=1200, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZV7P29X7m-",
        "colab_type": "code",
        "outputId": "140ed25e-ef63-4586-ca1c-0a05bd60e607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "%time training(ddcnn_rez2, 2, 2e-3, 0) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.78 - acc: 0.454 - valid loss : 1.25 - acc : 0.631 time taken: 14.52\n",
            "epoch 0 - batch [999/3968] - train loss: 0.68 - acc: 0.520 - valid loss : 1.07 - acc : 0.701 time taken: 14.58\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.40 - acc: 0.559 - valid loss : 0.92 - acc : 0.726 time taken: 14.66\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.27 - acc: 0.585 - valid loss : 1.00 - acc : 0.729 time taken: 14.64\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.20 - acc: 0.607 - valid loss : 0.88 - acc : 0.759 time taken: 14.54\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.16 - acc: 0.622 - valid loss : 0.92 - acc : 0.776 time taken: 14.47\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.635 - valid loss : 0.87 - acc : 0.807 time taken: 14.27\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.11 - acc: 0.646 - valid loss : 0.82 - acc : 0.823 time taken: 13.24\n",
            "epoch 1 - batch [499/3968] - train loss: 0.71 - acc: 0.782 - valid loss : 0.84 - acc : 0.818 time taken: 13.90\n",
            "epoch 1 - batch [999/3968] - train loss: 0.35 - acc: 0.783 - valid loss : 0.86 - acc : 0.818 time taken: 13.92\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.23 - acc: 0.785 - valid loss : 0.86 - acc : 0.816 time taken: 13.92\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.17 - acc: 0.785 - valid loss : 0.86 - acc : 0.824 time taken: 13.96\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.14 - acc: 0.786 - valid loss : 0.87 - acc : 0.834 time taken: 14.06\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.11 - acc: 0.787 - valid loss : 0.87 - acc : 0.829 time taken: 14.05\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.10 - acc: 0.787 - valid loss : 0.88 - acc : 0.818 time taken: 14.15\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.08 - acc: 0.788 - valid loss : 0.89 - acc : 0.824 time taken: 13.13\n",
            "CPU times: user 2min 54s, sys: 49.6 s, total: 3min 43s\n",
            "Wall time: 3min 46s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDCNN(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (dcnn): DCNN_rez_block(\n",
              "    (conv1): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (conv2): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (conv3): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.2, inplace=False)\n",
              "    (do2): Dropout(p=0.2, inplace=False)\n",
              "    (do3): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (do1): Dropout(p=0.2, inplace=False)\n",
              "  (do2): Dropout(p=0.2, inplace=False)\n",
              "  (do3): Dropout(p=0.2, inplace=False)\n",
              "  (cnn1): Conv1d(300, 50, kernel_size=(4,), stride=(1,), padding=(3,))\n",
              "  (cnn2): Conv1d(300, 50, kernel_size=(6,), stride=(1,), padding=(5,))\n",
              "  (cnn3): Conv1d(300, 50, kernel_size=(8,), stride=(1,), padding=(7,))\n",
              "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=300, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLd7kJ6rm8j3",
        "colab_type": "code",
        "outputId": "792475b5-41cb-4431-bc68-b47077348891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "%time training(ddcnn_rez3, 2, 2e-3, 0) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.70 - acc: 0.484 - valid loss : 1.20 - acc : 0.649 time taken: 15.91\n",
            "epoch 0 - batch [999/3968] - train loss: 0.66 - acc: 0.545 - valid loss : 1.08 - acc : 0.692 time taken: 15.98\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.39 - acc: 0.580 - valid loss : 1.04 - acc : 0.729 time taken: 15.94\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.26 - acc: 0.606 - valid loss : 1.00 - acc : 0.750 time taken: 16.01\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.20 - acc: 0.625 - valid loss : 0.93 - acc : 0.779 time taken: 16.02\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.15 - acc: 0.640 - valid loss : 0.87 - acc : 0.779 time taken: 16.06\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.653 - valid loss : 0.77 - acc : 0.788 time taken: 16.04\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.10 - acc: 0.663 - valid loss : 0.80 - acc : 0.793 time taken: 14.86\n",
            "epoch 1 - batch [499/3968] - train loss: 0.62 - acc: 0.811 - valid loss : 0.78 - acc : 0.795 time taken: 15.66\n",
            "epoch 1 - batch [999/3968] - train loss: 0.30 - acc: 0.816 - valid loss : 0.77 - acc : 0.798 time taken: 15.58\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.20 - acc: 0.817 - valid loss : 0.78 - acc : 0.804 time taken: 15.73\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.15 - acc: 0.817 - valid loss : 0.79 - acc : 0.798 time taken: 15.69\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.12 - acc: 0.819 - valid loss : 0.79 - acc : 0.802 time taken: 15.71\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.10 - acc: 0.819 - valid loss : 0.80 - acc : 0.810 time taken: 15.75\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.08 - acc: 0.821 - valid loss : 0.81 - acc : 0.807 time taken: 15.75\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.06 - acc: 0.822 - valid loss : 0.81 - acc : 0.804 time taken: 14.73\n",
            "CPU times: user 3min 10s, sys: 58.8 s, total: 4min 9s\n",
            "Wall time: 4min 11s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDCNN(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (dcnn): DCNN_rez_block(\n",
              "    (conv1): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (conv2): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (conv3): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.1, inplace=False)\n",
              "    (do2): Dropout(p=0.1, inplace=False)\n",
              "    (do3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (do1): Dropout(p=0.1, inplace=False)\n",
              "  (do2): Dropout(p=0.1, inplace=False)\n",
              "  (do3): Dropout(p=0.1, inplace=False)\n",
              "  (cnn1): Conv1d(300, 100, kernel_size=(4,), stride=(1,), padding=(3,))\n",
              "  (cnn2): Conv1d(300, 100, kernel_size=(6,), stride=(1,), padding=(5,))\n",
              "  (cnn3): Conv1d(300, 100, kernel_size=(8,), stride=(1,), padding=(7,))\n",
              "  (bn): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.1, inplace=False)\n",
              "  (linear): Linear(in_features=600, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UBTCn8gfvto",
        "colab_type": "code",
        "outputId": "c8dc1757-2332-4f17-f969-269a04d04b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "%time training(dcnn_rez1, 2, 2e-3, 1e-4)  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.82 - acc: 0.446 - valid loss : 1.15 - acc : 0.628 time taken: 26.83\n",
            "epoch 0 - batch [999/3968] - train loss: 0.66 - acc: 0.523 - valid loss : 1.12 - acc : 0.680 time taken: 26.98\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.38 - acc: 0.567 - valid loss : 0.99 - acc : 0.705 time taken: 27.06\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.26 - acc: 0.596 - valid loss : 0.88 - acc : 0.750 time taken: 27.08\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.20 - acc: 0.618 - valid loss : 0.87 - acc : 0.762 time taken: 27.09\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.15 - acc: 0.635 - valid loss : 0.81 - acc : 0.785 time taken: 27.15\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.649 - valid loss : 0.82 - acc : 0.790 time taken: 26.99\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.10 - acc: 0.660 - valid loss : 0.83 - acc : 0.792 time taken: 24.86\n",
            "epoch 1 - batch [499/3968] - train loss: 0.60 - acc: 0.818 - valid loss : 0.80 - acc : 0.796 time taken: 26.20\n",
            "epoch 1 - batch [999/3968] - train loss: 0.30 - acc: 0.819 - valid loss : 0.77 - acc : 0.798 time taken: 26.27\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.20 - acc: 0.819 - valid loss : 0.81 - acc : 0.809 time taken: 26.19\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.15 - acc: 0.820 - valid loss : 0.79 - acc : 0.796 time taken: 26.31\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.12 - acc: 0.820 - valid loss : 0.78 - acc : 0.806 time taken: 26.39\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.10 - acc: 0.821 - valid loss : 0.78 - acc : 0.799 time taken: 26.42\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.08 - acc: 0.821 - valid loss : 0.77 - acc : 0.802 time taken: 26.36\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.07 - acc: 0.822 - valid loss : 0.79 - acc : 0.806 time taken: 24.66\n",
            "CPU times: user 4min 37s, sys: 2min 21s, total: 6min 58s\n",
            "Wall time: 7min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCNN(\n",
              "  (word_embedding): Embedding(113157, 500)\n",
              "  (net): DCNN_rez_block(\n",
              "    (conv1): Conv1d(500, 500, kernel_size=(5,), stride=(1,), padding=(4,))\n",
              "    (conv2): Conv1d(500, 500, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
              "    (conv3): Conv1d(500, 500, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.2, inplace=False)\n",
              "    (do2): Dropout(p=0.2, inplace=False)\n",
              "    (do3): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (bn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=500, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "udcd1KyjnwdZ",
        "outputId": "eb63ba3c-4103-4b4f-bcc1-79e3435bf52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "%time training(dcnn_rez2, 2, 2e-3, 0)    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.79 - acc: 0.451 - valid loss : 1.26 - acc : 0.621 time taken: 13.09\n",
            "epoch 0 - batch [999/3968] - train loss: 0.68 - acc: 0.517 - valid loss : 1.12 - acc : 0.677 time taken: 13.12\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.39 - acc: 0.559 - valid loss : 1.03 - acc : 0.725 time taken: 13.15\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.27 - acc: 0.587 - valid loss : 0.96 - acc : 0.737 time taken: 13.15\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.20 - acc: 0.608 - valid loss : 0.95 - acc : 0.756 time taken: 13.15\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.16 - acc: 0.625 - valid loss : 0.89 - acc : 0.781 time taken: 13.15\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.638 - valid loss : 0.85 - acc : 0.787 time taken: 13.07\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.11 - acc: 0.649 - valid loss : 0.79 - acc : 0.793 time taken: 12.07\n",
            "epoch 1 - batch [499/3968] - train loss: 0.72 - acc: 0.778 - valid loss : 0.79 - acc : 0.790 time taken: 12.75\n",
            "epoch 1 - batch [999/3968] - train loss: 0.35 - acc: 0.781 - valid loss : 0.79 - acc : 0.798 time taken: 12.67\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.23 - acc: 0.783 - valid loss : 0.78 - acc : 0.790 time taken: 12.69\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.17 - acc: 0.784 - valid loss : 0.78 - acc : 0.799 time taken: 12.76\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.13 - acc: 0.786 - valid loss : 0.78 - acc : 0.802 time taken: 12.75\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.11 - acc: 0.787 - valid loss : 0.78 - acc : 0.809 time taken: 12.79\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.10 - acc: 0.788 - valid loss : 0.78 - acc : 0.802 time taken: 12.80\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.08 - acc: 0.788 - valid loss : 0.77 - acc : 0.806 time taken: 12.03\n",
            "CPU times: user 2min 28s, sys: 54.8 s, total: 3min 23s\n",
            "Wall time: 3min 25s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCNN(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (net): DCNN_rez_block(\n",
              "    (conv1): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (conv2): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (conv3): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.2, inplace=False)\n",
              "    (do2): Dropout(p=0.2, inplace=False)\n",
              "    (do3): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=300, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmAoRjl8m5FE",
        "colab_type": "code",
        "outputId": "b40198ed-0296-4bd9-9f04-ac99e6c5b472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "%time training(dcnn_rez3, 2, 2e-3, 1e-4)    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.88 - acc: 0.427 - valid loss : 1.42 - acc : 0.586 time taken: 14.94\n",
            "epoch 0 - batch [999/3968] - train loss: 0.70 - acc: 0.501 - valid loss : 1.19 - acc : 0.621 time taken: 14.97\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.41 - acc: 0.543 - valid loss : 1.05 - acc : 0.694 time taken: 15.02\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.28 - acc: 0.573 - valid loss : 0.91 - acc : 0.745 time taken: 15.03\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.21 - acc: 0.596 - valid loss : 0.90 - acc : 0.759 time taken: 15.04\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.17 - acc: 0.613 - valid loss : 0.89 - acc : 0.767 time taken: 15.08\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.628 - valid loss : 0.90 - acc : 0.768 time taken: 15.06\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.11 - acc: 0.639 - valid loss : 0.86 - acc : 0.788 time taken: 14.11\n",
            "epoch 1 - batch [499/3968] - train loss: 0.74 - acc: 0.774 - valid loss : 0.84 - acc : 0.790 time taken: 14.78\n",
            "epoch 1 - batch [999/3968] - train loss: 0.37 - acc: 0.774 - valid loss : 0.83 - acc : 0.801 time taken: 14.73\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.24 - acc: 0.776 - valid loss : 0.83 - acc : 0.812 time taken: 14.76\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.18 - acc: 0.777 - valid loss : 0.82 - acc : 0.812 time taken: 14.81\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.14 - acc: 0.779 - valid loss : 0.82 - acc : 0.801 time taken: 14.80\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.12 - acc: 0.780 - valid loss : 0.82 - acc : 0.802 time taken: 14.78\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.10 - acc: 0.780 - valid loss : 0.81 - acc : 0.810 time taken: 14.81\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.08 - acc: 0.781 - valid loss : 0.80 - acc : 0.821 time taken: 13.87\n",
            "CPU times: user 2min 47s, sys: 1min 6s, total: 3min 54s\n",
            "Wall time: 3min 56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCNN(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (net): DCNN_rez_block(\n",
              "    (conv1): Conv1d(300, 500, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (conv2): Conv1d(300, 500, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (conv3): Conv1d(300, 500, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
              "    (relu1): ReLU()\n",
              "    (relu2): ReLU()\n",
              "    (relu3): ReLU()\n",
              "    (do1): Dropout(p=0.3, inplace=False)\n",
              "    (do2): Dropout(p=0.3, inplace=False)\n",
              "    (do3): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (bn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=500, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb8Ig9NBX7mz",
        "colab_type": "code",
        "outputId": "856b5d86-272c-49d7-d605-d4b40d5a0d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "%time training(dcnn1, 2, 2e-3, 0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 2.06 - acc: 0.343 - valid loss : 1.42 - acc : 0.558 time taken: 11.57\n",
            "epoch 0 - batch [999/3968] - train loss: 0.66 - acc: 0.466 - valid loss : 1.14 - acc : 0.672 time taken: 11.58\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.39 - acc: 0.525 - valid loss : 1.00 - acc : 0.712 time taken: 11.47\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.27 - acc: 0.561 - valid loss : 0.98 - acc : 0.729 time taken: 11.35\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.20 - acc: 0.588 - valid loss : 0.95 - acc : 0.748 time taken: 11.22\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.16 - acc: 0.608 - valid loss : 0.92 - acc : 0.754 time taken: 11.24\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.13 - acc: 0.624 - valid loss : 0.91 - acc : 0.771 time taken: 11.18\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.10 - acc: 0.636 - valid loss : 0.85 - acc : 0.767 time taken: 10.45\n",
            "epoch 1 - batch [499/3968] - train loss: 0.73 - acc: 0.780 - valid loss : 0.82 - acc : 0.779 time taken: 11.14\n",
            "epoch 1 - batch [999/3968] - train loss: 0.36 - acc: 0.782 - valid loss : 0.81 - acc : 0.798 time taken: 11.13\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.24 - acc: 0.782 - valid loss : 0.81 - acc : 0.801 time taken: 11.11\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.18 - acc: 0.782 - valid loss : 0.82 - acc : 0.790 time taken: 11.08\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.14 - acc: 0.783 - valid loss : 0.82 - acc : 0.790 time taken: 11.04\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.12 - acc: 0.784 - valid loss : 0.82 - acc : 0.787 time taken: 11.08\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.10 - acc: 0.785 - valid loss : 0.81 - acc : 0.801 time taken: 11.09\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.08 - acc: 0.786 - valid loss : 0.81 - acc : 0.796 time taken: 10.40\n",
            "CPU times: user 2min 12s, sys: 44.2 s, total: 2min 56s\n",
            "Wall time: 2min 58s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCNN(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (net): DCNN_block(\n",
              "    (conv1): Conv1d(300, 300, kernel_size=(3,), stride=(1,))\n",
              "    (conv2): Conv1d(300, 300, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
              "    (conv3): Conv1d(300, 300, kernel_size=(3,), stride=(1,), dilation=(4,))\n",
              "    (net): Sequential(\n",
              "      (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,))\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.2, inplace=False)\n",
              "      (3): Conv1d(300, 300, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
              "      (4): ReLU()\n",
              "      (5): Dropout(p=0.2, inplace=False)\n",
              "      (6): Conv1d(300, 300, kernel_size=(3,), stride=(1,), dilation=(4,))\n",
              "      (7): ReLU()\n",
              "      (8): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=300, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ditzSZC9fMM2",
        "outputId": "3aac93a0-75a0-4292-a0df-ad45c56d3ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "%time training(lstm1, 2, 2e-3, 0)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 - batch [499/3968] - train loss: 1.99 - acc: 0.371 - valid loss : 1.43 - acc : 0.574 time taken: 16.95\n",
            "epoch 0 - batch [999/3968] - train loss: 0.70 - acc: 0.475 - valid loss : 1.30 - acc : 0.663 time taken: 16.96\n",
            "epoch 0 - batch [1499/3968] - train loss: 0.41 - acc: 0.526 - valid loss : 1.15 - acc : 0.708 time taken: 17.05\n",
            "epoch 0 - batch [1999/3968] - train loss: 0.29 - acc: 0.557 - valid loss : 1.09 - acc : 0.728 time taken: 17.09\n",
            "epoch 0 - batch [2499/3968] - train loss: 0.22 - acc: 0.579 - valid loss : 1.12 - acc : 0.717 time taken: 17.18\n",
            "epoch 0 - batch [2999/3968] - train loss: 0.18 - acc: 0.595 - valid loss : 0.99 - acc : 0.739 time taken: 17.17\n",
            "epoch 0 - batch [3499/3968] - train loss: 0.15 - acc: 0.609 - valid loss : 1.03 - acc : 0.739 time taken: 17.29\n",
            "epoch 0 - batch [3967/3968] - train loss: 0.12 - acc: 0.619 - valid loss : 1.02 - acc : 0.759 time taken: 16.03\n",
            "epoch 1 - batch [499/3968] - train loss: 0.90 - acc: 0.724 - valid loss : 0.99 - acc : 0.759 time taken: 17.01\n",
            "epoch 1 - batch [999/3968] - train loss: 0.44 - acc: 0.726 - valid loss : 1.00 - acc : 0.759 time taken: 17.05\n",
            "epoch 1 - batch [1499/3968] - train loss: 0.30 - acc: 0.726 - valid loss : 0.99 - acc : 0.756 time taken: 16.99\n",
            "epoch 1 - batch [1999/3968] - train loss: 0.22 - acc: 0.728 - valid loss : 1.00 - acc : 0.760 time taken: 17.08\n",
            "epoch 1 - batch [2499/3968] - train loss: 0.17 - acc: 0.729 - valid loss : 0.98 - acc : 0.765 time taken: 17.02\n",
            "epoch 1 - batch [2999/3968] - train loss: 0.15 - acc: 0.729 - valid loss : 0.98 - acc : 0.770 time taken: 17.15\n",
            "epoch 1 - batch [3499/3968] - train loss: 0.12 - acc: 0.730 - valid loss : 0.97 - acc : 0.764 time taken: 17.15\n",
            "epoch 1 - batch [3967/3968] - train loss: 0.10 - acc: 0.731 - valid loss : 0.97 - acc : 0.770 time taken: 16.10\n",
            "CPU times: user 3min 25s, sys: 1min 3s, total: 4min 28s\n",
            "Wall time: 4min 31s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_clf(\n",
              "  (word_embedding): Embedding(113157, 300)\n",
              "  (net): LSTM(300, 300, num_layers=2, dropout=0.5)\n",
              "  (relu): ReLU()\n",
              "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=300, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_6OH2OCfLDV",
        "colab": {}
      },
      "source": [
        "models = [dcnn1, dcnn_rez1, dcnn_rez2, dcnn_rez3, lstm1, ddcnn_rez1, ddcnn_rez2, ddcnn_rez3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-CHlD2gdZyin",
        "outputId": "968051db-a6af-4b23-bb7e-2a8d0d06ee27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "valid_preds_dict = {}\n",
        "test_preds_dict = {}\n",
        "for i, model in enumerate(models):\n",
        "    _, valid_preds, valid_labels, valid_loss = validate(model, criterion)\n",
        "    print(\"accuracy: \", accuracy(valid_preds, valid_labels))\n",
        "    valid_preds_ = predict(model, valid_loader)\n",
        "    print(\"verify predicts won't mess up order\", accuracy(valid_preds, valid_preds))\n",
        "    print(\"generating test preds\")\n",
        "    test_preds = predict(model, test_loader)\n",
        "    \n",
        "    valid_preds_dict[\"model_{}\".format(i)] = valid_preds_\n",
        "    test_preds_dict[\"model_{}\".format(i)] = test_preds\n",
        "    "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.7962674961119751\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8055987558320373\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8055987558320373\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8211508553654744\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.7698289269051322\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8227060653188181\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8242612752721618\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n",
            "accuracy:  0.8040435458786936\n",
            "verify predicts won't mess up order 1.0\n",
            "generating test preds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRjHcsXcX7nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_preds = pd.DataFrame(valid_preds_dict)\n",
        "test_preds = pd.DataFrame(test_preds_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPpzh8y-X7nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_preds[\"majority_vote\"] = valid_preds.apply(lambda row: row.value_counts().index[0].astype(int), axis=1)\n",
        "test_preds[\"majority_vote\"] = test_preds.apply(lambda row: row.value_counts().index[0].astype(int), axis=1)\n",
        "valid_preds[\"pred_label\"] = valid_preds[\"majority_vote\"].apply(lambda x: label_vocab.i2w[x])\n",
        "test_preds[\"pred_label\"] = test_preds[\"majority_vote\"].apply(lambda x: label_vocab.i2w[x])\n",
        "valid_preds.to_csv(\"valid_predictions.csv\", index=False)\n",
        "test_preds.to_csv(\"test_predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZNOdQZgX7nM",
        "colab_type": "code",
        "outputId": "d128bed3-7755-4036-e228-cdd937023154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "valid_preds.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_0</th>\n",
              "      <th>model_1</th>\n",
              "      <th>model_2</th>\n",
              "      <th>model_3</th>\n",
              "      <th>model_4</th>\n",
              "      <th>model_5</th>\n",
              "      <th>model_6</th>\n",
              "      <th>model_7</th>\n",
              "      <th>majority_vote</th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>sports and recreation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>sports and recreation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>sports and recreation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>media and drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>philosophy and religion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model_0  model_1  model_2  ...  model_7  majority_vote               pred_label\n",
              "0       13       13       13  ...       13             13    sports and recreation\n",
              "1       13       13       13  ...       13             13    sports and recreation\n",
              "2       13       13       13  ...       13             13    sports and recreation\n",
              "3        7        7        7  ...        7              7          media and drama\n",
              "4        7        7        7  ...        4             11  philosophy and religion\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbhy7umBX7nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MA0-uWKIVkVG"
      },
      "source": [
        "#### Prediction\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-4DtMu9MCp7r",
        "outputId": "60ae40a7-1b80-40d2-bbb3-5e5382e7fb02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(accuracy(valid_preds[\"majority_vote\"].values, valid_labels))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8413685847589425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vP3cFgX2Cq0R",
        "colab": {}
      },
      "source": [
        "with open(\"dev_results.txt\", \"w\") as f:\n",
        "    for s in label_vocab.map_index2words(valid_preds.majority_vote.values):\n",
        "        f.write(s + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3XvHomXE63x",
        "colab": {}
      },
      "source": [
        "with open(\"test_results.txt\", \"w\") as f:\n",
        "    for s in label_vocab.map_index2words(test_preds.majority_vote.values):\n",
        "        f.write(s + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kerzFQVNFWY_",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}